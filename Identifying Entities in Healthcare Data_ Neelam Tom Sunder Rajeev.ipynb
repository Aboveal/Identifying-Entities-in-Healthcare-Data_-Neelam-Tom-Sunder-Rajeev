{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268f2db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycrf in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: sklearn-crfsuite in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (0.9.8)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (1.16.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (0.8.9)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm>=2.0->sklearn-crfsuite) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycrf\n",
    "!pip install sklearn-crfsuite\n",
    "import spacy\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31680654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a04e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function t process the file and return a sentence list\n",
    "def preprocess_inputfile(input_file):\n",
    "    i_file = open(input_file, 'r')\n",
    "    file_name = i_file.readlines()\n",
    "    i_file.close()\n",
    "    \n",
    "    output_list = []\n",
    "    \n",
    "    full_sentence = \" \"\n",
    "    \n",
    "    for each_word in file_name:\n",
    "        each_word = each_word.strip()\n",
    "        if each_word == \"\":\n",
    "            output_list.append(full_sentence)# to append the complete sentence to the output list\n",
    "            full_sentence = \"\" # for new sentence start\n",
    "        else:\n",
    "            if full_sentence:\n",
    "                full_sentence +=  \" \" + each_word\n",
    "            else:\n",
    "                full_sentence = each_word\n",
    "                \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e608f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = preprocess_inputfile('C:/Users/DELL/Downloads/train_sent')\n",
    "train_labels = preprocess_inputfile('C:/Users/DELL/Downloads/train_label')\n",
    "test_sentences = preprocess_inputfile('C:/Users/DELL/Downloads/test_sent')\n",
    "test_labels = preprocess_inputfile('C:/Users/DELL/Downloads/test_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c34660d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1) is:   All live births > or = 23 weeks at the University of Vermont in 1995 ( n = 2395 ) were retrospectively analyzed for delivery route , indication for cesarean , gestational age , parity , and practice group ( to reflect risk status )\n",
      "Label 1  is:   O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "****************************************************************************************************\n",
      "sentence 2) is: The total cesarean rate was 14.4 % ( 344 of 2395 ) , and the primary rate was 11.4 % ( 244 of 2144 )\n",
      "Label 2  is: O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "****************************************************************************************************\n",
      "sentence 3) is: Abnormal presentation was the most common indication ( 25.6 % , 88 of 344 )\n",
      "Label 3  is: O O O O O O O O O O O O O O O\n",
      "****************************************************************************************************\n",
      "sentence 4) is: The `` corrected '' cesarean rate ( maternal-fetal medicine and transported patients excluded ) was 12.4 % ( 273 of 2194 ) , and the `` corrected '' primary rate was 9.6 % ( 190 of 1975 )\n",
      "Label 4  is: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "****************************************************************************************************\n",
      "sentence 5) is: Arrest of dilation was the most common indication in both `` corrected '' subgroups ( 23.4 and 24.6 % , respectively )\n",
      "Label 5  is: O O O O O O O O O O O O O O O O O O O O O O\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Print first five sentences from the processed dataset\n",
    "for each_item in range(5):\n",
    "    print(f\"sentence {each_item+1}) is: {train_sentences[each_item]}\")\n",
    "    print(f\"Label {each_item+1}  is: {train_labels[each_item]}\")\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0191b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in processed train dataset is: 2599\n",
      "Number of sentences in processed test dataset is : 1056\n"
     ]
    }
   ],
   "source": [
    "## Count the number of sentences in the processed train and test dataset \n",
    "\n",
    "print(f\"Number of sentences in processed train dataset is: {len(train_sentences)}\")\n",
    "print(f\"Number of sentences in processed test dataset is : {len(test_sentences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a0828b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in processed train dataset is: 2599\n",
      "Number of sentences in processed test dataset is : 1056\n"
     ]
    }
   ],
   "source": [
    "## Count the number of labels in the processed train and test dataset \n",
    "\n",
    "print(f\"Number of sentences in processed train dataset is: {len(train_labels)}\")\n",
    "print(f\"Number of sentences in processed test dataset is : {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a5a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list to hold all the tokens which are either NOUN or PROPER NOUN\n",
    "noun_propn_tokens_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a608971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each token which is a NOUN or PROPN will be appended to the list \"noun_propn_tokens_list\"\n",
    "for sentences in (train_sentences, test_sentences):\n",
    "    for sent in sentences:\n",
    "        processed_sent = model(sent)\n",
    "        for each_token in processed_sent:\n",
    "            if each_token.pos_ == \"NOUN\" or each_token.pos_ == \"PROPN\":\n",
    "                noun_propn_tokens_list.append(each_token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac094186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series to hold the tokens which are either NOUN or PROPER NOUN\n",
    "df_noun_propn = pd.Series(noun_propn_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc7b207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print the top 25 most common tokens with NOUN or PROPN PoS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34dedd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patients        492\n",
       "treatment       281\n",
       "%               247\n",
       "cancer          200\n",
       "therapy         175\n",
       "study           152\n",
       "disease         141\n",
       "cell            140\n",
       "lung            116\n",
       "group            94\n",
       "chemotherapy     88\n",
       "gene             87\n",
       "effects          85\n",
       "results          78\n",
       "women            77\n",
       "use              74\n",
       "risk             71\n",
       "cases            71\n",
       "surgery          71\n",
       "analysis         70\n",
       "rate             67\n",
       "response         66\n",
       "survival         65\n",
       "children         64\n",
       "effect           63\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting then count of each token and sorting the data in top 25 most token counts\n",
    "df_noun_propn.value_counts().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6319aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining features for CRF\n",
    "\n",
    "# Let's define the features to get the feature value for one word.\n",
    "\n",
    "def getFeaturesForOneWord(sentence, pos, pos_tags):\n",
    "  word = sentence[pos]\n",
    "\n",
    "  features = [\n",
    "    'word.lower=' + word.lower(), # serves as word id\n",
    "    'word[-3:]=' + word[-3:],     # last three characters\n",
    "    'word[-2:]=' + word[-2:],     # last two characters\n",
    "    'word.isupper=%s' % word.isupper(),  # is the word in all uppercase\n",
    "    'word.isdigit=%s' % word.isdigit(),  # is the word a number\n",
    "    'word.startsWithCapital=%s' % word[0].isupper(), # is the word starting with a capital letter\n",
    "    'word.pos=' + pos_tags[pos]\n",
    "  ]\n",
    "\n",
    "  #Use the previous word also while defining features\n",
    "  if(pos > 0):\n",
    "    prev_word = sentence[pos-1]\n",
    "    features.extend([\n",
    "    'prev_word.lower=' + prev_word.lower(), \n",
    "    'prev_word.isupper=%s' % prev_word.isupper(),\n",
    "    'prev_word.isdigit=%s' % prev_word.isdigit(),\n",
    "    'prev_word.startsWithCapital=%s' % prev_word[0].isupper(),\n",
    "    'prev_word.pos=' + pos_tags[pos-1]\n",
    "  ])\n",
    "  # Mark the begining and the end words of a sentence correctly in the form of features.\n",
    "  else:\n",
    "    features.append('BEG') # feature to track begin of sentence \n",
    "\n",
    "  if(pos == len(sentence)-1):\n",
    "    features.append('END') # feature to track end of sentence\n",
    "\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4654536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting the features\n",
    "\n",
    "## Write a code/function to get the features for a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fc5fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get features for a sentence.\n",
    "def getFeaturesForOneSentence(sentence):\n",
    "    \n",
    "    # We need to get the pos_tags to be passed to the function\n",
    "    processed_sent = model(sentence)\n",
    "    postags = []\n",
    "    \n",
    "    for each_token in processed_sent:\n",
    "        postags.append(each_token.pos_)\n",
    "    \n",
    "    sentence_list = sentence.split()\n",
    "    return [getFeaturesForOneWord(sentence_list, pos, postags) for pos in range(len(sentence_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32522f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write a code/function to get the labels of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bb89674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the labels for a sentence.\n",
    "def getLabelsInListForOneSentence(labels):\n",
    "  return labels.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f2c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define input and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efdf1db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the features' values for each sentence as input variable for CRF model in test and the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b03d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [getFeaturesForOneSentence(sentence) for sentence in train_sentences]\n",
    "X_test = [getFeaturesForOneSentence(sentence) for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d16895d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the labels as the target variable for test and the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b48f4366",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = [getLabelsInListForOneSentence(labels) for labels in train_labels]\n",
    "Y_test = [getLabelsInListForOneSentence(labels) for labels in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "533ede25",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build the CRF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b3b1480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to not get the error AttributeError: 'CRF' object has no attribute 'keep_tempfiles'\n",
    "# pip install scikit-learn==0.22.2 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2189e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CRF model.\n",
    "crf = sklearn_crfsuite.CRF(max_iterations=100)\n",
    "try:\n",
    "    crf.fit(X_train, Y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e59bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61a049c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the labels of each of the tokens in each sentence of the test dataset that has been pre processed earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0009c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f8a748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the f1 score using the actual labels and the predicted labels of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b52411a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.9059\n"
     ]
    }
   ],
   "source": [
    "f1_score = metrics.flat_f1_score(Y_test, Y_pred, average='weighted')\n",
    "print(f\"F1 score is: {round(f1_score,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8d69a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identifying Diseases and Treatments using Custom NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d89c3659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty dictionary to hold diseases and their corresponding treatments\n",
    "D_T_dict = dict()\n",
    "\n",
    "for i in range(len(Y_pred)):\n",
    "    # Get the predicted labels of each test sentence into \"val\"\n",
    "    val = Y_pred[i]\n",
    "    \n",
    "    # Empty strings to store the values of Diseases and Treatments\n",
    "    Diseases = \"\"\n",
    "    Treatments = \"\"\n",
    "    \n",
    "    # Each loop will iterate through the individual labels and focus on mapping D and T labels\n",
    "    # with Diseases and Treatments within each sentence into a concatenated string\n",
    "    for j in range(len(val)):\n",
    "        if val[j] == 'D': # If label is D, it indicates a Disease \n",
    "            Diseases += test_sentences[i].split()[j] + \" \"\n",
    "        elif val[j] == 'T': # If label is T, it indicates a Treatment\n",
    "            Treatments += test_sentences[i].split()[j] + \" \"\n",
    "            \n",
    "    # Removes any extra whitespaces to either end of the string\n",
    "    Diseases = Diseases.lstrip().rstrip()\n",
    "    Treatments = Treatments.lstrip().rstrip()\n",
    "\n",
    "    # If Diseases and Treatments are blank, ignore them\n",
    "    # If Disease is not present in Dictionary, add it along with the corresponding treatment\n",
    "    # If Disease is present in the Dictionary, append the treatments for that diseases with existing\n",
    "    # treatments\n",
    "    if Diseases != \"\" and Treatments != \"\":\n",
    "        if Diseases in D_T_dict.keys():\n",
    "            treat_out = list(D_T_dict[Diseases])\n",
    "            treat_out.append(Treatments)\n",
    "            D_T_dict[Diseases] = treat_out\n",
    "        elif Diseases not in D_T_dict.keys():\n",
    "            D_T_dict[Diseases] = Treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe1833dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the treatment for the disease name: 'hereditary retinoblastoma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbd7f4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'radiotherapy'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_T_dict['hereditary retinoblastoma']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
